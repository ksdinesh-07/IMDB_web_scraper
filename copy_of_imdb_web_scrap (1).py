# -*- coding: utf-8 -*-
"""Copy of IMDB_web_scrap.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aaklVLicxsiFnEzu65hGhkDzv_V3jUe-
"""

# Install required packages
!pip install requests beautifulsoup4 pandas lxml

import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
from google.colab import files

def scrape_imdb_simple():
    """Scrape IMDb Top 250 using requests and BeautifulSoup"""
    print("Starting IMDb Top 250 Scraper...")

    # IMDb Top 250 URL
    url = "https://www.imdb.com/chart/top/"

    # Proper headers to mimic a real browser
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.9',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'none',
        'Cache-Control': 'max-age=0'
    }

    try:
        # Send GET request with headers
        print("Fetching IMDb page...")
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()

        # Parse HTML content
        soup = BeautifulSoup(response.content, 'html.parser')

        # Find the chart container
        chart = soup.find('div', {'data-testid': 'chart-layout-main-column'})

        if not chart:
            print("Could not find chart container")
            return []

        # Find all movie rows
        movie_rows = chart.find_all('li', class_='ipc-metadata-list-summary-item')

        print(f"Found {len(movie_rows)} movies")

        movies_data = []

        for index, row in enumerate(movie_rows[:250], 1):
            try:
                # Extract title
                title_element = row.find('h3', class_='ipc-title__text')
                if title_element:
                    title_text = title_element.get_text(strip=True)
                    # Remove ranking number
                    title = title_text.split('. ', 1)[1] if '. ' in title_text else title_text
                else:
                    title = "N/A"

                # Extract year
                year_element = row.find('span', class_='sc-479faa3c-8')
                if year_element:
                    year = year_element.get_text(strip=True)
                else:
                    # Alternative selector for year
                    year_alt = row.find('span', class_='cli-title-metadata-item')
                    year = year_alt.get_text(strip=True) if year_alt else "N/A"

                # Extract rating
                rating_element = row.find('span', class_='ipc-rating-star--rating')
                if rating_element:
                    rating = rating_element.get_text(strip=True)
                else:
                    rating = "N/A"

                # Store movie data
                movie_data = {
                    'Rank': index,
                    'Title': title,
                    'Year': year,
                    'IMDb_Rating': rating
                }

                movies_data.append(movie_data)
                print(f"Processed {index:3d}. {title[:40]:40} ({year}) - Rating: {rating}")

            except Exception as e:
                print(f"Error scraping movie {index}: {str(e)}")
                continue

        return movies_data

    except requests.exceptions.RequestException as e:
        print(f"Network error during scraping: {str(e)}")
        return []
    except Exception as e:
        print(f"Error during scraping: {str(e)}")
        return []

def scrape_imdb_pandas():
    """Scrape IMDb using pandas read_html"""
    print("Using pandas method...")

    url = "https://www.imdb.com/chart/top/"

    # Headers for pandas request
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept-Language': 'en-US,en;q=0.9'
    }

    try:
        # Read tables from the URL with headers
        tables = pd.read_html(url, header=0)

        if not tables:
            print("No tables found")
            return None

        # The first table should contain our data
        df = tables[0]
        print(f"Successfully extracted {len(df)} movies")
        return df

    except Exception as e:
        print(f"Error with pandas method: {str(e)}")
        return None

# Execute the scraper
print("Starting IMDb Top 250 Movie Scraping...")
movies_data = scrape_imdb_simple()

if movies_data:
    # Create DataFrame
    df = pd.DataFrame(movies_data)

    # Display first few rows
    print("\nSample of scraped data:")
    print(df.head(10))

    # Save to CSV
    csv_filename = "imdb_top_250_movies.csv"
    df.to_csv(csv_filename, index=False)
    print(f"\nData saved to: {csv_filename}")

    # Display basic statistics
    print(f"\nScraping Summary:")
    print(f"Total movies scraped: {len(df)}")

    # Convert rating to numeric for statistics
    df['IMDb_Rating'] = pd.to_numeric(df['IMDb_Rating'], errors='coerce')
    print(f"Average rating: {df['IMDb_Rating'].mean():.2f}")
    print(f"Highest rating: {df['IMDb_Rating'].max():.2f}")
    print(f"Lowest rating: {df['IMDb_Rating'].min():.2f}")

else:
    # If BeautifulSoup fails, try pandas method
    print("\nBeautifulSoup method failed, trying pandas method...")
    df = scrape_imdb_pandas()

    if df is not None:
        print("\nSample of scraped data:")
        print(df.head(10))

        # Save to CSV
        csv_filename = "imdb_top_250_movies.csv"
        df.to_csv(csv_filename, index=False)
        print(f"\nData saved to: {csv_filename}")
    else:
        print("Both scraping methods failed")

# Display results and download file
if 'df' in locals() and not df.empty:
    print("Scraping Results:")
    print(f"Total movies: {len(df)}")

    # Display all data
    pd.set_option('display.max_rows', None)
    pd.set_option('display.width', 1000)
    print("\nComplete Dataset:")
    print(df)

    # Download the CSV file
    files.download('imdb_top_250_movies.csv')
    print("\nCSV file downloaded to your computer!")

    # Basic statistics
    print(f"\nBasic Statistics:")
    print(f"Dataset shape: {df.shape}")
    if 'IMDb_Rating' in df.columns:
        ratings = pd.to_numeric(df['IMDb_Rating'], errors='coerce')
        print(f"Average rating: {ratings.mean():.2f}")
        print(f"Highest rating: {ratings.max():.2f}")
        print(f"Lowest rating: {ratings.min():.2f}")

else:
    print("No data available to display.")

!ls